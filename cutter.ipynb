{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    \"\"\"\n",
    "    Construct an double linked observer tree by nodes    \n",
    "    \"\"\"\n",
    "    def __init__(self, left=None,right=None,op='atomic',interval=[],depth=0,atomic=None):\n",
    "        \"\"\"   \n",
    "        args:\n",
    "            left(node): left child node\n",
    "            right(node): right child node\n",
    "            op(str):operator type\n",
    "            interval(list): interval of the opeartor\n",
    "        \"\"\"\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.op = op\n",
    "        self.interval = interval\n",
    "        self.depth = depth\n",
    "        self.atomic = atomic\n",
    "        self.parents = set()\n",
    "        \n",
    "    def add_parent(self, node):\n",
    "        self.parents.add(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTree(file):\n",
    "    \"\"\"\n",
    "    Construct the big observer tree from assembly file\n",
    "    args:\n",
    "        assembly file name\n",
    "    return:\n",
    "        root node\n",
    "    \"\"\"\n",
    "    Opnum = lambda word: word[0]+str(int(word[1:]))# remove redundant '0's, e.g. convert 's000' -> 's0'\n",
    "    name2node,node2name,lineCount = {},{},0\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            words = line.strip().lower().split()        \n",
    "            if(len(words)==0 or words[0][0]=='#'):# skip the empty line and commented line\n",
    "                continue\n",
    "            for i,word in enumerate(words[1:]):\n",
    "                if(not word.isdigit()):\n",
    "                    words[i+1]=Opnum(word)\n",
    "            print(words)\n",
    "            if(words[0]=='load' or words[0]=='load_ft'):\n",
    "#                 if(words[1] not in name2node):\n",
    "#                     name2node[words[1]] = node(atomic=words[1])\n",
    "#                     node2name[name2node[words[1]]] = words[1]\n",
    "#                 curNode = node(left=name2node[words[1]],op='load',depth=name2node[words[1]].depth+1)# count from 1\n",
    "                curNode = node(op='load',atomic=words[1])# count from 1\n",
    "                \n",
    "            elif(words[0]=='not'):\n",
    "                curNode = node(left=name2node[words[1]],op=words[0],interval=[int(words[2])],depth=name2node[words[1]].depth+1)\n",
    "            elif(words[0]=='boxbox'):\n",
    "                curNode = node(left=name2node[words[1]],op=words[0],interval=[int(words[2])],depth=name2node[words[1]].depth+1)\n",
    "            elif(words[0]=='boxdot'):\n",
    "                curNode = node(left=name2node[words[1]],op=words[0],interval=[int(words[2]),int(words[3])],depth=name2node[words[1]].depth+1)\n",
    "            elif(words[0]=='and' or words[0]=='until'):\n",
    "                curNode = node(left=name2node[words[1]],right=name2node[words[2]],op=words[0],depth=max(name2node[words[1]].depth,name2node[words[2]].depth)+1)\n",
    "                name2node[words[2]].add_parent(curNode)# assign parent node\n",
    "            elif(words[0]=='end'):\n",
    "                curNode = node(left=name2node[words[1]],op=words[0],depth=name2node[words[1]].depth+1)                \n",
    "            name2node['s'+str(lineCount)] = curNode\n",
    "            if(words[1] in name2node):\n",
    "                name2node[words[1]].add_parent(curNode)# assign parent node\n",
    "            node2name[curNode] = 's'+str(lineCount)\n",
    "            lineCount+=1\n",
    "    return curNode,name2node,node2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['load', 'a0']\n",
      "['load', 'a1']\n",
      "['and', 's0', 's1']\n",
      "['load', 'a0']\n",
      "['boxdot', 's3', '3', '5']\n",
      "['and', 's2', 's4']\n",
      "['end', 's5']\n"
     ]
    }
   ],
   "source": [
    "file = \"assembly.txt\"\n",
    "root,name2node,node2name = MakeTree(file)\n",
    "cutSet={'s2','s4'}# user defined cut\n",
    "#cutSet={'s0'}\n",
    "cutNodeSet = {name2node[word] for word in cutSet}# map cutSet to node\n",
    "\n",
    "class group:\n",
    "    class miniGroup:\n",
    "        def __init__(self):\n",
    "            self.member = set()\n",
    "        def add(self,node):\n",
    "            self.member.add(node)\n",
    "        def update(self, mini_group):\n",
    "            self.member.update(mini_group.member)\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tagUsed = 0\n",
    "        self.tag2group = {}\n",
    "        self.node2tag = {}\n",
    "    \n",
    "    def getNodeTag(self, node):\n",
    "        return self.node2tag[node]\n",
    "    \n",
    "    def getNewTag(self):\n",
    "        # construct a new tag label and map the new tag to a new miniGroup\n",
    "        self.tagUsed += 1\n",
    "        self.tag2group[self.tagUsed] = group.miniGroup()\n",
    "        return self.tagUsed\n",
    "    \n",
    "    def add(self, node, tag):\n",
    "        # map a node to the tag\n",
    "        self.node2tag[node] = tag\n",
    "        if(tag not in self.tag2group):\n",
    "            self.tag2group[tag] = group.miniGroup()\n",
    "        self.tag2group[tag].add(node)\n",
    "    \n",
    "    def combine_group(self, tag1, tag2):\n",
    "        # comine two groups (merge tag2 group into tag1 group)\n",
    "        miniGroup1 = self.tag2group[tag1]\n",
    "        miniGroup2 = self.tag2group[tag2]\n",
    "        if not(miniGroup1 is miniGroup2): # test if the two references point to the same miniGroup\n",
    "            miniGroup1.update(miniGroup2)\n",
    "            self.tag2group[tag2] = miniGroup1\n",
    "        \n",
    "bigGroup = group()\n",
    "\n",
    "# recursive programming\n",
    "# DFS the observer tree to do partition\n",
    "def assignGroup(root,setTag):\n",
    "    if(root):\n",
    "        if(root in bigGroup.node2tag):\n",
    "            oldTag = bigGroup.getNodeTag(root)\n",
    "            bigGroup.combine_group(oldTag,setTag)\n",
    "        else:\n",
    "            #if((root in cutNodeSet) or (len(root.parents)==0)):# initialize a new partition\n",
    "            if((root in cutNodeSet) or (root.op=='end')):# initialize a new partition\n",
    "                setTag = bigGroup.getNewTag()\n",
    "            bigGroup.add(root,setTag)\n",
    "            assignGroup(root.left,setTag)\n",
    "            assignGroup(root.right,setTag)\n",
    "                   \n",
    "assignGroup(root,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "end\n",
      "and\n",
      "--------------------\n",
      "and\n",
      "load\n",
      "load\n",
      "--------------------\n",
      "boxdot\n",
      "load\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# map the group tag to the list of nodes in the group\n",
    "group2nodes={}\n",
    "# DFS to get all the node and its group\n",
    "def DFS(root):\n",
    "    if(root):\n",
    "        certainGroup = bigGroup.tag2group[bigGroup.node2tag[root]]\n",
    "        if(certainGroup not in group2nodes):\n",
    "            group2nodes[certainGroup] = []    \n",
    "        group2nodes[certainGroup].append(root)\n",
    "        DFS(root.left)\n",
    "        DFS(root.right)\n",
    "\n",
    "DFS(root)\n",
    "\n",
    "for keys in group2nodes:\n",
    "    print('--------------------')\n",
    "    for nodes in group2nodes[keys]:\n",
    "        print(nodes.op)\n",
    "print('--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topologicalSort(output,group,group2node, cutNodeSet):\n",
    "    '''\n",
    "    do topological sort of the tree branch\n",
    "    '''\n",
    "    print(output)\n",
    "    visited = set()\n",
    "    stack = []\n",
    "    for nodes in group2node[group]:\n",
    "        if(nodes not in visited):\n",
    "            topSortUntil(nodes, visited, stack, group2node[group], cutNodeSet)\n",
    "    stack.reverse()\n",
    "    for e in stack:\n",
    "        print(e.op)\n",
    "    print()\n",
    "    return stack\n",
    "    \n",
    "def topSortUntil(nodes, visited, stack, boundedGroup, cutNodeSet):\n",
    "    visited.add(nodes)\n",
    "    if(len(nodes.parents)==0 or nodes in cutNodeSet):\n",
    "        stack.append(nodes)\n",
    "    else:\n",
    "        for parent in nodes.parents:\n",
    "            if(parent not in visited and parent in boundedGroup):\n",
    "                topSortUntil(parent,visited, stack, boundedGroup,cutNodeSet)\n",
    "        stack.append(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_0\n",
      "and\n",
      "end\n",
      "\n",
      "core_1\n",
      "load\n",
      "load\n",
      "and\n",
      "\n",
      "core_2\n",
      "load\n",
      "boxdot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputFile = lambda i: 'core_'+str(i)\n",
    "node2core = {}\n",
    "sortResult = {}\n",
    "\n",
    "#sortResult = {i:topologicalSort(outputFile(i),group,group2nodes,cutNodeSet) for i,group in enumerate(group2nodes)}\n",
    "for i,group in enumerate(group2nodes):\n",
    "    for nodes in group2nodes[group]:\n",
    "        node2core[nodes] = i\n",
    "    sortResult[i] = topologicalSort(outputFile(i),group,group2nodes,cutNodeSet) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command On Processing Core_ 0 :\n",
      "loadc c1_s2\n",
      "loadc c2_s4\n",
      "and s0 s1\n",
      "end s2\n",
      "---------------------------------\n",
      "Command On Processing Core_ 1 :\n",
      "load a1\n",
      "load a0\n",
      "and s1 s0\n",
      "endc s2 c0_s2\n",
      "---------------------------------\n",
      "Command On Processing Core_ 2 :\n",
      "load a0\n",
      "boxdot s0 3 5\n",
      "endc s1 c0_s4\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate output\n",
    "for i in range(len(sortResult)):\n",
    "    lineCount = 0\n",
    "    prog = []\n",
    "    node2line = {}\n",
    "    for results in sortResult[i]: # traverse the stack of each core\n",
    "        if results.left and results.left not in sortResult[i]: # fetch result from another core, add extra 'load' operation\n",
    "            result_left = node(op='loadc',atomic='c'+str(node2core[results.left])+'_'+node2name[results.left])\n",
    "            result_left.add_parent(results)\n",
    "            node2core[result_left] = i\n",
    "            node2line[result_left] = lineCount\n",
    "            prog.append('loadc '+'c'+str(node2core[results.left])+'_'+node2name[results.left])\n",
    "            results.left = result_left # establish new connection\n",
    "            lineCount += 1\n",
    "        if results.right: # and/until operation\n",
    "            if results.right not in sortResult[i]: # fetch result from another core\n",
    "                result_right = node(op='loadc',atomic='c'+str(node2core[results.right])+'_'+node2name[results.right])\n",
    "                result_right.add_parent(results)\n",
    "                node2core[result_right] = i\n",
    "                node2line[result_right] = lineCount\n",
    "                prog.append('loadc '+'c'+str(node2core[results.right])+'_'+node2name[results.right])\n",
    "                results.right = result_right # establish new connection\n",
    "                lineCount += 1\n",
    "        node2line[results] = lineCount\n",
    "        if results.op == 'load':\n",
    "            prog.append(results.op+' '+results.atomic)        \n",
    "        elif results.op == 'not' or results.op == 'end':\n",
    "            prog.append(results.op+' s'+str(node2line[results.left]))\n",
    "        elif results.op == 'boxbox':\n",
    "            prog.append(results.op+' s'+str(node2line[results.left])+' '+str(results.interval[0]))\n",
    "        elif results.op == 'boxdot':\n",
    "            prog.append(results.op+' s'+str(node2line[results.left])+' '+str(results.interval[0])+' '+str(results.interval[1]))\n",
    "        elif results.op == 'and' or results.op == 'until':\n",
    "            prog.append(results.op+' s'+str(node2line[results.left])+' s'+str(node2line[results.right]))  \n",
    "        lineCount += 1\n",
    "        \n",
    "        for parent in results.parents:\n",
    "            if parent not in sortResult[i]: # the result will be sent to other core\n",
    "                prog.append('endc'+' s'+str(lineCount-1)+' c'+str(node2core[parent])+'_'+node2name[results])\n",
    "                lineCount += 1\n",
    "\n",
    "    print('Command On Processing Core_',i,':')\n",
    "    for x in prog:\n",
    "        print(x)\n",
    "    print('---------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
